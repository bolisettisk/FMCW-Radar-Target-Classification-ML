{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99b6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from FMCW_Data_Simulation_Library import Tx_gen, Get_Target_Params, Rx_mpt_gen, Rx_add_noise\n",
    "from FMCW_Data_Simulation_Library import FFT_gen, Target_Data_gen, ML_Model_Tester\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c9d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_max = 200 # Maximum range of the target\n",
    "c = 3e8 # Speed of light\n",
    "range_resolution = 1 # FMCW radar range resolution\n",
    "Nd = 64 # Number of chirps\n",
    "Nr = 256 # Numnber samples per chirp\n",
    "fc = 77e9 # FMCW radar carrier frequency\n",
    "endle_time = 6.3e-6 # Time delay between ramps\n",
    "range_window = np.hamming(Nr) # hamming window for range FFT data\n",
    "doppler_window = np.hamming(Nd) # hamming window for doppler FFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260f75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx, t, slope, Tchirp = Tx_gen(range_max, c, range_resolution, Nd, Nr, fc)\n",
    "Fs = Nr/Tchirp # Sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e942b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Model_Test_Data_gen(Shapes_dict, data_samples, SNR_dB, c, Nd, Nr, fc, Tx, t, slope, Fs, \n",
    "                    endle_time, range_window, doppler_window):\n",
    "    \n",
    "    Shapes = list(Shapes_dict.keys()) # Extracting target shape names\n",
    "    Shapes_list = Shapes*(int(data_samples/2)) # Generating required number of target shape samples\n",
    "    random.shuffle(Shapes_list) # Shuffling the list of target shape names for randomisation\n",
    "    target_classifications = [Shapes_dict[key] for key in Shapes_list] # Generating equivalent randomised target classifications\n",
    "    \n",
    "    target_data = [] # An empty list to store FMCW radar data\n",
    "    status_counter = 0 # Status counter\n",
    "    for Shape in Shapes_list: # Iterating for each shape in randomised Shapes list\n",
    "        [min_range, max_range, min_velocity, max_velocity, min_shape_dim, \n",
    "         max_shape_dim, ranges, \n",
    "         velocities, shape_dims] = Get_Target_Params(Shape, 1000) # Generating target parameters for each shape\n",
    "        \n",
    "        target_range = random.choice(ranges) # Randomising input target range for the current shape\n",
    "        target_velocity = random.choice(velocities) # Randomising input target velocity for the current shape\n",
    "        target_shape_dims = random.choice(shape_dims) # Randomising input target shape dimensions for the current shape\n",
    "        \n",
    "        Rx_Signals_mpt_sqr = Rx_mpt_gen(Nd, Nr, Tx, endle_time, target_range, \n",
    "                                        target_velocity, t, slope, c, fc, shape=Shape, \n",
    "                                        shape_dim=target_shape_dims) # Genearting FMCW Rx multi-point target return signal\n",
    "        Rx_Signals_mpt_sqr_noise = Rx_add_noise(Rx_Signals_mpt_sqr, SNR_dB) # Adding noise with a required signal-to-noise ratio\n",
    "        \n",
    "        Output_Data = FFT_gen(Rx_Signals_mpt_sqr_noise, Fs, Nr, c, slope,\n",
    "                              range_window, doppler_window, range_window_en=True,\n",
    "                              doppler_window_en=True, range_plot=False, doppler_fft=True, \n",
    "                              doppler_plot_linear=False, doppler_plot_log=False, \n",
    "                              doppler_data_format='Linear', range_data_format='Linear') # Generating range or doppler FFT outputs\n",
    "\n",
    "\n",
    "\n",
    "        target_data.append(Output_Data.T) # Apending FMCW radar data for each iteration of target shape\n",
    "        \n",
    "        status_counter += 1\n",
    "        print(\"--- {}dB SNR: {}% complete! ---\".format(SNR_dB, int((status_counter/data_samples)*100)),end=\"\\r\") # Printing status\n",
    "        \n",
    "        \n",
    "    y_test = np.array(target_classifications) # Converting target classification list to an array\n",
    "    X_test = np.array(target_data) # Converting radar data to an array\n",
    "    \n",
    "    return X_test, y_test, Shapes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145fd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Artefact_Gen(Model_index, target_directory, Shapes_dict, SNR_dB, car_path, person_path):\n",
    "    \"\"\"\n",
    "    Model_index: {'CNN_Classifier.joblib': 0, 'GBC_Classifier.joblib': 1, 'LSTM_Classifier.joblib': 2, \n",
    "    'MLP_Classifier.joblib': 3, 'RNN_Classifier.joblib': 4}\n",
    "    \"\"\"    \n",
    "    ML_models = os.listdir(target_directory) # Location of the directory with saved ML models\n",
    "    Model = ML_models[Model_index] # Selecting an ML model based on index value\n",
    "    ML_path = target_directory + '/' + Model # Path to the selected ML model\n",
    "    ML_model = joblib.load(ML_path) # Importing the previously trained machine learning model from the target directory\n",
    "\n",
    "    X_test, y_test, Shape = ML_Model_Test_Data_gen(Shapes_dict, 2, SNR_dB, c, Nd, Nr, fc, Tx, t, \n",
    "                           slope, Fs, endle_time, range_window, doppler_window) # Generating simulated data\n",
    "    \n",
    "    car_samples = os.listdir(car_path) # Extracting list of all samples from Car class\n",
    "    car_sample_path = random.choice(car_samples) # Selecting a random sample from Car class\n",
    "    car_data = np.load(os.path.join(car_path, car_sample_path)) # Loading the ransom sample from Car class\n",
    "    car_data = np.expand_dims(car_data, axis=0) # Transforming the loaded sample to required shape\n",
    "    person_samples = os.listdir(person_path) # Extracting list of all samples from Person class\n",
    "    person_sample_path = random.choice(person_samples) # Selecting a random sample from Person class\n",
    "    person_data = np.load(os.path.join(person_path, person_sample_path)) # Loading the ransom sample from Person class\n",
    "    person_data = np.expand_dims(person_data, axis=0) # Transforming the loaded sample to required shape\n",
    "    \n",
    "    X_test = np.concatenate((X_test, car_data), axis=0) # Creating a single array of simulated and CARRADA data\n",
    "    y_test = np.concatenate((y_test, np.reshape(np.array([2]), (1,))), axis=0) # Creating a single array of simulated and CARRADA data\n",
    "    Shape.append('Car') # List of input classes\n",
    "    X_test = np.concatenate((X_test, person_data), axis=0)\n",
    "    y_test = np.concatenate((y_test, np.reshape(np.array([3]), (1,))), axis=0)\n",
    "    Shape.append('Person') # List of input classes\n",
    "    Shape = np.array(Shape)\n",
    "    \n",
    "    X_test_index = np.arange(X_test.shape[0]) # Index of X_test array to shuffle the data \n",
    "    np.random.shuffle(X_test_index) # Shuffling the index values (to be used to shuffle all arrays in same order)\n",
    "    \n",
    "    X_test  = X_test[X_test_index] # Shuffling X_test array\n",
    "    y_test =  y_test[X_test_index] # Shuffling y_test array\n",
    "    Shape = Shape[X_test_index] # Shuffling Shape array\n",
    "    \n",
    "    \n",
    "\n",
    "    predictions_dict = {0: \"Square\", 1: \"Triangle\", 2: \"Car\", 3: \"Person\"} # A dictionary of predicted values and corresponding class names\n",
    "    if Model in ['LSTM_Classifier.joblib', 'RNN_Classifier.joblib']:\n",
    "        y_test = to_categorical(y_test, len(predictions_dict)) # Data transformation as required by the models\n",
    "    if Model in ['GBC_Classifier.joblib']:\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1) # Data transformation as required by the models\n",
    "        \n",
    "    y_pred = ML_model.predict(X_test) # Making predictions using the selected model \n",
    "    \n",
    "    Shapes_Predicted = [] # An empty list to store predicted target class information\n",
    "    for i in y_pred:  # Iterating for each predicted value\n",
    "        Shapes_Predicted.append(predictions_dict[np.argmax(i)]) # Transforming the predicted array to corresponding class name\n",
    "\n",
    "    clear_output()\n",
    "    print(\"Input Shapes are: {}\".format(list(Shape)))\n",
    "    print(\"Predicted Shapes are: {}\".format(list(Shapes_Predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c722391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shapes are: ['Person', 'Triangle', 'Car', 'Square']\n",
      "Predicted Shapes are: ['Person', 'Square', 'Car', 'Square']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model_index: {'CNN_Classifier.joblib': 0, 'GBC_Classifier.joblib': 1, 'LSTM_Classifier.joblib': 2, \n",
    "'MLP_Classifier.joblib': 3, 'RNN_Classifier.joblib': 4}\n",
    "\"\"\" \n",
    "Shapes_dict = {\"Square\":0, \"Triangle\":1} # Required target shapes to simulate\n",
    "target_directory = \"ML_Model_Doppler_3dB_Full\"\n",
    "car_path = '../data/Car'\n",
    "person_path = '../data/Person'\n",
    "\n",
    "Artefact_Gen(0, target_directory, Shapes_dict, -5, car_path, person_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff369d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53163b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c82e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06563566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac5626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91652032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
